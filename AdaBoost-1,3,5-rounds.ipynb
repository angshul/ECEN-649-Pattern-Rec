{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "import hashlib\n",
    "import glob\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import *\n",
    "\n",
    "\n",
    "import requests\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyunpack import Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Archive(\"dataset.zip\").extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/home/angshul1994/dataset\"\n",
    "train_data_dir=os.path.join(data_dir,\"trainset\")\n",
    "train_faces=os.path.join(train_data_dir,\"faces\")\n",
    "train_non_faces=os.path.join(train_data_dir,\"non-faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"C:\\\\Users\\\\ANGSHUL\\\\Downloads\\\\dataset\"\n",
    "train_data_dir=os.path.join(data_dir,\"trainset\")\n",
    "train_faces=os.path.join(train_data_dir,\"faces\")\n",
    "train_non_faces=os.path.join(train_data_dir,\"non-faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_image_files = glob.glob(os.path.join(train_faces, '**', '*.png'), recursive=True)\n",
    "len(face_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_image_files=glob.glob(os.path.join(train_non_faces, '**', '*.png'), recursive=True)\n",
    "len(background_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(img: Image.Image):\n",
    "    return np.array(img).astype(np.float32) / 255.\n",
    "\n",
    "def integral_image(img: np.ndarray):\n",
    "    integral = np.cumsum(np.cumsum(img, axis=0), axis=1)\n",
    "    return np.pad(integral, (1, 1), 'constant', constant_values=(0, 0))[:-1, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE=19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(self, x: int, y: int, width: int, height: int):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "    def __call__(self, integral_image: np.ndarray) -> float:\n",
    "        try:\n",
    "            return np.sum(np.multiply(integral_image[self.y_pos, self.x_pos], self.coeffs))\n",
    "        except IndexError as e:\n",
    "            raise IndexError(str(e) + ' in ' + str(self))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(x={self.x}, y={self.y}, width={self.width}, height={self.height})'    \n",
    "              \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature2h(Feature):\n",
    "    def __init__(self, x: int, y: int, width: int, height: int):\n",
    "        super().__init__(x, y, width, height)\n",
    "        hw = width // 2\n",
    "        self.x_pos = [x,      x + hw,     x,          x + hw,\n",
    "                         x + hw, x + width,  x + hw,     x + width]\n",
    "        self.y_pos = [y,      y,          y + height, y + height,\n",
    "                         y,      y,          y + height, y + height]\n",
    "        self.coeffs   = [1,     -1,         -1,          1,\n",
    "                         -1,     1,          1,         -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature2v(Feature):\n",
    "    def __init__(self, x: int, y: int, width: int, height: int):\n",
    "        super().__init__(x, y, width, height)\n",
    "        hh = height // 2        \n",
    "        self.x_pos = [x,      x + width,  x,          x + width,\n",
    "                         x,      x + width,  x,          x + width]\n",
    "        self.y_pos = [y,      y,          y + hh,     y + hh,\n",
    "                         y + hh, y + hh,     y + height, y + height]\n",
    "        self.coeffs   = [-1,     1,          1,         -1,\n",
    "                         1,     -1,         -1,          1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature3h(Feature):\n",
    "    def __init__(self, x: int, y: int, width: int, height: int):\n",
    "        super().__init__(x, y, width, height)\n",
    "        tw = width // 3\n",
    "        self.x_pos = [x,        x + tw,    x,          x + tw,\n",
    "                         x + tw,   x + 2*tw,  x + tw,     x + 2*tw,\n",
    "                         x + 2*tw, x + width, x + 2*tw,   x + width]\n",
    "        self.y_pos = [y,        y,         y + height, y + height,\n",
    "                         y,        y,         y + height, y + height,\n",
    "                         y,        y,         y + height, y + height]\n",
    "        self.coeffs   = [-1,       1,         1,         -1,\n",
    "                          1,      -1,        -1,          1,\n",
    "                         -1,       1,         1,         -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature3v(Feature):\n",
    "    def __init__(self, x: int, y: int, width: int, height: int):\n",
    "        super().__init__(x, y, width, height)\n",
    "        th = height // 3\n",
    "        self.x_pos = [x,        x + width,  x,          x + width,\n",
    "                         x,        x + width,  x,          x + width,\n",
    "                         x,        x + width,  x,          x + width]\n",
    "        self.y_pos = [y,        y,          y + th,     y + th,\n",
    "                         y + th,   y + th,     y + 2*th,   y + 2*th,\n",
    "                         y + 2*th, y + 2*th,   y + height, y + height]\n",
    "        self.coeffs   = [-1,        1,         1,         -1,\n",
    "                          1,       -1,        -1,          1,\n",
    "                         -1,        1,         1,         -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature4(Feature):\n",
    "    def __init__(self, x: int, y: int, width: int, height: int):\n",
    "        super().__init__(x, y, width, height)\n",
    "        hw = width // 2\n",
    "        hh = height // 2\n",
    "        self.x_pos = [x,      x + hw,     x,          x + hw,     # upper row\n",
    "                         x + hw, x + width,  x + hw,     x + width,\n",
    "                         x,      x + hw,     x,          x + hw,     # lower row\n",
    "                         x + hw, x + width,  x + hw,     x + width]\n",
    "        self.y_pos = [y,      y,          y + hh,     y + hh,     # upper row\n",
    "                         y,      y,          y + hh,     y + hh,\n",
    "                         y + hh, y + hh,     y + height, y + height, # lower row\n",
    "                         y + hh, y + hh,     y + height, y + height]\n",
    "        self.coeffs   = [1,     -1,         -1,          1,          # upper row\n",
    "                         -1,     1,          1,         -1,\n",
    "                         -1,     1,          1,         -1,          # lower row\n",
    "                          1,    -1,         -1,          1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Size = NamedTuple('Size', [('height', int), ('width', int)])\n",
    "Location = NamedTuple('Location', [('top', int), ('left', int)])\n",
    "\n",
    "\n",
    "def get_positions(base_shape: Size, window_size: int = WINDOW_SIZE):\n",
    "    return (Location(left=x, top=y)\n",
    "            for x in range(0, window_size-base_shape.width+1) \n",
    "            for y in range(0, window_size-base_shape.height+1))\n",
    "\n",
    "def get_shapes(base_shape: Size, window_size: int = WINDOW_SIZE):\n",
    "    base_height = base_shape.height\n",
    "    base_width = base_shape.width\n",
    "    return (Size(height=height, width=width)\n",
    "            for width in range(base_width, window_size + 1, base_width)\n",
    "            for height in range(base_height, window_size + 1, base_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature2h features: 17100\n",
      "Number of feature2v features: 17100\n",
      "Number of feature3h features: 10830\n",
      "Number of feature3v features: 10830\n",
      "Number of feature4 features:  8100\n",
      "Total number of features:     63960\n"
     ]
    }
   ],
   "source": [
    "feature2h = list(Feature2h(location.left, location.top, shape.width, shape.height)\n",
    "                 for shape in get_shapes(Size(height=1, width=2), WINDOW_SIZE)\n",
    "                 for location in get_positions(shape, WINDOW_SIZE))\n",
    "\n",
    "feature2v = list(Feature2v(location.left, location.top, shape.width, shape.height)\n",
    "                 for shape in get_shapes(Size(height=2, width=1), WINDOW_SIZE)\n",
    "                 for location in get_positions(shape, WINDOW_SIZE))\n",
    "\n",
    "feature3h = list(Feature3h(location.left, location.top, shape.width, shape.height)\n",
    "                 for shape in get_shapes(Size(height=1, width=3), WINDOW_SIZE)\n",
    "                 for location in get_positions(shape, WINDOW_SIZE))\n",
    "\n",
    "feature3v = list(Feature3v(location.left, location.top, shape.width, shape.height)\n",
    "                 for shape in get_shapes(Size(height=3, width=1), WINDOW_SIZE)\n",
    "                 for location in get_positions(shape, WINDOW_SIZE))\n",
    "\n",
    "feature4  = list(Feature4(location.left, location.top, shape.width, shape.height)\n",
    "                 for shape in get_shapes(Size(height=2, width=2), WINDOW_SIZE)\n",
    "                 for location in get_positions(shape, WINDOW_SIZE))\n",
    "\n",
    "features = feature2h + feature2v + feature3h + feature3v + feature4\n",
    "\n",
    "print(f'Number of feature2h features: {len(feature2h)}')\n",
    "print(f'Number of feature2v features: {len(feature2v)}')\n",
    "print(f'Number of feature3h features: {len(feature3h)}')\n",
    "print(f'Number of feature3v features: {len(feature3v)}')\n",
    "print(f'Number of feature4 features:  {len(feature4)}')\n",
    "print(f'Total number of features:     {len(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_data(p: int, n: int, face_files, background_files):\n",
    "    xs = []\n",
    "    xs.extend([image_to_array(Image.open(f).convert('L')) for f in random.sample(face_image_files, p)])\n",
    "    xs.extend([image_to_array(Image.open(f).convert('L')) for f in np.random.choice(background_image_files, n, replace=True)])\n",
    "    ys = np.hstack([np.ones((p,)), np.zeros((n,))])\n",
    "    return np.array(xs), ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mean: 0.4319107234477997, standard deviation: 0.21371206641197205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_samples, _ = build_data(499, 2000, face_image_files, background_image_files)\n",
    "\n",
    "sample_mean = image_samples.mean()\n",
    "sample_std = image_samples.std()\n",
    "del image_samples\n",
    "\n",
    "print(f'Sample mean: {sample_mean}, standard deviation: {sample_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(p: int, n: int, face_files, background_files, mean: float = sample_mean, std: float = sample_std):\n",
    "    xs, ys = build_data(p, n, face_files, background_files)\n",
    "    xs=(xs-mean)/std\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = normalize(499, 2000, face_image_files, background_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2499, 19, 19), (2499, 20, 20))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xis = np.array([integral_image(x) for x in xs])\n",
    "xs.shape, xis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threshold = NamedTuple('Threshold', [('threshold', float), ('polarity', float)])\n",
    "\n",
    "ClassifierResult = NamedTuple('ClassifierResult', [('threshold', float), ('polarity', int), \n",
    "                                                   ('classification_error', float),\n",
    "                                                   ('classifier', Callable[[np.ndarray], float])])\n",
    "\n",
    "WeakClassifier = NamedTuple('WeakClassifier', [('threshold', float), ('polarity', int), \n",
    "                                               ('alpha', float), \n",
    "                                               ('classifier', Callable[[np.ndarray], float])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weak_classifier(x: np.ndarray, classifier: WeakClassifier) -> float:\n",
    "    polarity=classifier.polarity\n",
    "    theta=classifier.threshold\n",
    "    feature=classifier.classifier\n",
    "    return (np.sign((polarity * theta) - (polarity * feature(x))) + 1) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
    "    sum_hypotheses = 0.\n",
    "    sum_alphas = 0.\n",
    "    for c in weak_classifiers:\n",
    "        sum_hypotheses += c.alpha * get_weak_classifier(x, c)\n",
    "        sum_alphas += c.alpha\n",
    "    return 1 if (sum_hypotheses >= .5*sum_alphas) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_threshold(ys: np.ndarray, ws: np.ndarray, zs: np.ndarray):  \n",
    "    # Sort according to score\n",
    "    p = np.argsort(zs)\n",
    "    zs, ys, ws = zs[p], ys[p], ws[p]\n",
    "    \n",
    "    # Determine the best threshold: build running sums\n",
    "    s_minus, s_plus = 0., 0.\n",
    "    t_minus, t_plus = 0., 0.\n",
    "    s_minuses, s_pluses = [], []\n",
    "    \n",
    "    for y, w in zip(ys, ws):\n",
    "        if y < .5:\n",
    "            s_minus += w\n",
    "            t_minus += w\n",
    "        else:\n",
    "            s_plus += w\n",
    "            t_plus += w\n",
    "        s_minuses.append(s_minus)\n",
    "        s_pluses.append(s_plus)\n",
    "    \n",
    "    # Determine the best threshold: select optimal threshold.\n",
    "    min_e = float('inf')\n",
    "    min_z=0 \n",
    "    polarity=0\n",
    "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
    "        error_1 = s_p + (t_minus - s_m)\n",
    "        error_2 = s_m + (t_plus - s_p)\n",
    "        if error_1 < min_e:\n",
    "            min_e = error_1\n",
    "            min_z = z\n",
    "            polarity = -1\n",
    "        elif error_2 < min_e:\n",
    "            min_e = error_2\n",
    "            min_z = z\n",
    "            polarity = 1\n",
    "    return Threshold(threshold=min_z, polarity=polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(f: Feature, xis: np.ndarray, ys: np.ndarray, ws: np.ndarray, parallel: Optional[Parallel] = None) -> ClassifierResult:   \n",
    "    if parallel is None:\n",
    "        parallel = Parallel(n_jobs=-1, backend='threading')\n",
    "    \n",
    "    # Determine all feature values\n",
    "    zs = np.array(parallel(delayed(f)(x) for x in xis))\n",
    "    \n",
    "    # Determine the best threshold\n",
    "    result = get_threshold(ys, ws, zs)\n",
    "            \n",
    "    # Determine the classification error\n",
    "    classification_error = 0.\n",
    "    for x, y, w in zip(xis, ys, ws):\n",
    "        h = (np.sign((result.polarity *result.threshold) - (result.polarity * f(x))) + 1) // 2\n",
    "        classification_error += w * np.abs(h - y)\n",
    "            \n",
    "    return ClassifierResult(threshold=result.threshold, polarity=result.polarity, \n",
    "                            classification_error=classification_error, classifier=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(w: np.ndarray) -> np.ndarray:\n",
    "    return w / w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_check= 2000\n",
    "random_prob = 0.25\n",
    "\n",
    "def build_weak_classifiers(prefix: str, num_features: int, xis: np.ndarray, ys: np.ndarray, features: List[Feature], ws: Optional[np.ndarray] = None) -> Tuple[List[WeakClassifier], List[float]]:\n",
    "    if ws is None:\n",
    "        m = len(ys[ys < .5])  # number of negative example\n",
    "        l = len(ys[ys > .5])  # number of positive examples\n",
    "\n",
    "        # Initialize the weights\n",
    "        ws = np.zeros_like(ys)\n",
    "        ws[ys < .5] = 1./(2.*m)\n",
    "        ws[ys > .5] = 1./(2.*l)\n",
    "    \n",
    "    # Keep track of the history of the example weights.\n",
    "    w_history = [ws]\n",
    "\n",
    "    total_start_time = datetime.now()\n",
    "    with Parallel(n_jobs=-1, backend='threading') as parallel:\n",
    "        weak_classifiers = []  # type: List[WeakClassifier]\n",
    "        for t in range(num_features):\n",
    "            print(f'Building weak classifier {t+1}/{num_features} ...')\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            # Normalize the weights\n",
    "            ws = normalize_weights(ws)\n",
    "            \n",
    "            status_counter = status_check\n",
    "\n",
    "            # Select best weak classifier for this round\n",
    "            best = ClassifierResult(polarity=0, threshold=0, classification_error=float('inf'), classifier=None)\n",
    "            for i, f in enumerate(features):\n",
    "                status_counter -= 1\n",
    "                improved = False\n",
    "\n",
    "                # Python runs singlethreaded. To speed things up,\n",
    "                # we're only anticipating every other feature, give or take.\n",
    "                if random_prob < 1.:\n",
    "                    skip_probability = np.random.random()\n",
    "                    if skip_probability > random_prob:\n",
    "                        continue\n",
    "\n",
    "                result = create_features(f, xis, ys, ws, parallel)\n",
    "                if result.classification_error < best.classification_error:\n",
    "                    improved = True\n",
    "                    best = result\n",
    "\n",
    "                # Print status every couple of iterations.\n",
    "                if improved or status_counter == 0:\n",
    "                    current_time = datetime.now()\n",
    "                    duration = current_time - start_time\n",
    "                    total_duration = current_time - total_start_time\n",
    "                    status_counter = status_check\n",
    "                    if improved:\n",
    "                        print(f't={t+1}/{num_features} {total_duration.total_seconds():.2f}s ({duration.total_seconds():.2f}s in this stage) {i+1}/{len(features)} {100*i/len(features):.2f}% evaluated. Classification error improved to {best.classification_error:.5f} using {str(best.classifier)} ...')\n",
    "                    else:\n",
    "                        print(f't={t+1}/{num_features} {total_duration.total_seconds():.2f}s ({duration.total_seconds():.2f}s in this stage) {i+1}/{len(features)} {100*i/len(features):.2f}% evaluated.')\n",
    "\n",
    "            # After the best classifier was found, determine alpha\n",
    "            beta = best.classification_error / (1 - best.classification_error)\n",
    "            alpha = np.log(1. / beta)\n",
    "            \n",
    "            # Build the weak classifier\n",
    "            classifier = WeakClassifier(threshold=best.threshold, polarity=best.polarity, classifier=best.classifier, alpha=alpha)\n",
    "            \n",
    "            # Update the weights for misclassified examples\n",
    "            for i, (x, y) in enumerate(zip(xis, ys)):\n",
    "                h = get_weak_classifier(x, classifier)\n",
    "                e = np.abs(h - y)\n",
    "                ws[i] = ws[i] * np.power(beta, 1-e)\n",
    "                \n",
    "            # Register this weak classifier           \n",
    "            weak_classifiers.append(classifier)\n",
    "            w_history.append(ws)\n",
    "        \n",
    "    \n",
    "    print(f'Done building {num_features} weak classifiers.')\n",
    "    return weak_classifiers, w_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir=os.path.join(data_dir,\"testset\")\n",
    "test_faces=os.path.join(test_data_dir,\"faces\")\n",
    "test_non_faces=os.path.join(test_data_dir,\"non-faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_image_files_test = glob.glob(os.path.join(test_faces, '**', '*.png'), recursive=True)\n",
    "background_image_files_test=glob.glob(os.path.join(test_non_faces, '**', '*.png'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_samples_test, _ = build_data(471, 2000, face_image_files_test, background_image_files_test)\n",
    "\n",
    "sample_mean = image_samples_test.mean()\n",
    "sample_std = image_samples_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xs, test_ys = normalize(471, 2000,face_image_files_test, background_image_files_test)\n",
    "test_xis = np.array([integral_image(x) for x in test_xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores = NamedTuple('PredictionStats', [('tn', int), ('fp', int), ('fn', int), ('tp', int)])\n",
    "\n",
    "def predict(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[np.ndarray, predicted_scores]:\n",
    "    c = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = c.ravel()\n",
    "    return c, predicted_scores(tn=tn, fp=fp, fn=fn, tp=tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building weak classifier 1/1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-51fd85f81679>:19: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"find_best_threshold\" failed type inference due to: Invalid use of Function(<class 'float'>) with argument(s) of type(s): (Literal[str](inf))\n",
      " * parameterized\n",
      "In definition 0:\n",
      "    TypeError: float() only support for numbers\n",
      "    raised from /home/angshul1994/.local/lib/python3.6/site-packages/numba/typing/builtins.py:889\n",
      "In definition 1:\n",
      "    TypeError: float() only support for numbers\n",
      "    raised from /home/angshul1994/.local/lib/python3.6/site-packages/numba/typing/builtins.py:889\n",
      "This error is usually caused by passing an argument of a type that is unsupported by the named function.\n",
      "[1] During: resolving callee type: Function(<class 'float'>)\n",
      "[2] During: typing of call at <ipython-input-29-51fd85f81679> (21)\n",
      "\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 21:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    min_e = float('inf')\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "<ipython-input-29-51fd85f81679>:19: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"find_best_threshold\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"find_best_threshold\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 20:\n",
      "@jit\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 20:\n",
      "@jit\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/ir_utils.py:1969: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 's_minuses' of function 'find_best_threshold'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/ir_utils.py:1969: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 's_pluses' of function 'find_best_threshold'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "<ipython-input-26-e47a16af2a40>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"weak_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-26-e47a16af2a40> (4)\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 4:\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "    <source elided>\n",
      "    # return 1. if (polarity * f(x)) < (polarity * theta) else 0.\n",
      "    return (np.sign((polarity * theta) - (polarity * f(x))) + 1) // 2\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"weak_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 2:\n",
      "@jit\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 2:\n",
      "@jit\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=1/1 1.63s (1.63s in this stage) 1/63960 0.00% evaluated. Classification error improved to 0.33722 using Feature2h(x=0, y=0, width=2, height=1) ...\n",
      "t=1/1 2.19s (2.19s in this stage) 5/63960 0.01% evaluated. Classification error improved to 0.26680 using Feature2h(x=0, y=4, width=2, height=1) ...\n",
      "t=1/1 5.46s (5.45s in this stage) 29/63960 0.04% evaluated. Classification error improved to 0.25766 using Feature2h(x=1, y=9, width=2, height=1) ...\n",
      "t=1/1 14.92s (14.91s in this stage) 106/63960 0.16% evaluated. Classification error improved to 0.24651 using Feature2h(x=5, y=10, width=2, height=1) ...\n",
      "t=1/1 22.11s (22.11s in this stage) 160/63960 0.25% evaluated. Classification error improved to 0.17865 using Feature2h(x=8, y=7, width=2, height=1) ...\n",
      "t=1/1 59.20s (59.20s in this stage) 491/63960 0.77% evaluated. Classification error improved to 0.15235 using Feature2h(x=8, y=4, width=2, height=2) ...\n",
      "t=1/1 101.68s (101.68s in this stage) 805/63960 1.26% evaluated. Classification error improved to 0.15057 using Feature2h(x=8, y=2, width=2, height=3) ...\n",
      "t=1/1 102.21s (102.21s in this stage) 806/63960 1.26% evaluated. Classification error improved to 0.14934 using Feature2h(x=8, y=3, width=2, height=3) ...\n",
      "t=1/1 142.55s (142.54s in this stage) 1104/63960 1.72% evaluated. Classification error improved to 0.14333 using Feature2h(x=8, y=3, width=2, height=4) ...\n",
      "t=1/1 255.71s (255.71s in this stage) 1889/63960 2.95% evaluated. Classification error improved to 0.13258 using Feature2h(x=8, y=2, width=2, height=7) ...\n",
      "t=1/1 256.24s (256.24s in this stage) 1890/63960 2.95% evaluated. Classification error improved to 0.12758 using Feature2h(x=8, y=3, width=2, height=7) ...\n",
      "t=1/1 288.06s (288.06s in this stage) 2115/63960 3.31% evaluated. Classification error improved to 0.12682 using Feature2h(x=8, y=2, width=2, height=8) ...\n",
      "t=1/1 337.02s (337.02s in this stage) 2512/63960 3.93% evaluated. Classification error improved to 0.12658 using Feature2h(x=8, y=1, width=2, height=10) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-e47a16af2a40>:6: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"run_weak_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-26-e47a16af2a40> (8)\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 8:\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "    return weak_classifier(x=x, f=c.classifier, polarity=c.polarity, theta=c.threshold)\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"run_weak_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 7:\n",
      "@jit\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 7:\n",
      "@jit\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building 1 weak classifiers.\n"
     ]
    }
   ],
   "source": [
    "weak_classifiers_1, w_history = build_weak_classifiers('1 round', 1, xis, ys, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WeakClassifier(threshold=-2.403821110725403, polarity=1, alpha=1.9315405703473476, classifier=Feature2h(x=8, y=1, width=2, height=10))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_classifiers_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"strong_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-27-886b5b384fd2> (3)\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 3:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    sum_hypotheses = 0.\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "<ipython-input-27-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"strong_classifier\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"strong_classifier\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 2:\n",
      "@jit\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 2:\n",
      "@jit\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "<ipython-input-27-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"strong_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-27-886b5b384fd2> (5)\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"strong_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79 , False Positives: 181, False Negatives: 332\n"
     ]
    }
   ],
   "source": [
    "ys_strong = np.array([strong_classifier(x, weak_classifiers_1) for x in test_xis])\n",
    "c, s = predict(test_ys, ys_strong)\n",
    "print(f'Accuracy: {(s.tp+s.tn)/(s.tp+s.fp+s.tn+s.fn):.2f} , False Positives: {s.fp}, False Negatives: {s.fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building weak classifier 1/5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-51fd85f81679>:19: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"find_best_threshold\" failed type inference due to: Invalid use of Function(<class 'float'>) with argument(s) of type(s): (Literal[str](inf))\n",
      " * parameterized\n",
      "In definition 0:\n",
      "    TypeError: float() only support for numbers\n",
      "    raised from /home/angshul1994/.local/lib/python3.6/site-packages/numba/typing/builtins.py:889\n",
      "In definition 1:\n",
      "    TypeError: float() only support for numbers\n",
      "    raised from /home/angshul1994/.local/lib/python3.6/site-packages/numba/typing/builtins.py:889\n",
      "This error is usually caused by passing an argument of a type that is unsupported by the named function.\n",
      "[1] During: resolving callee type: Function(<class 'float'>)\n",
      "[2] During: typing of call at <ipython-input-29-51fd85f81679> (21)\n",
      "\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 21:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    min_e = float('inf')\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "<ipython-input-29-51fd85f81679>:19: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"find_best_threshold\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"find_best_threshold\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 20:\n",
      "@jit\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 20:\n",
      "@jit\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/ir_utils.py:1969: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 's_minuses' of function 'find_best_threshold'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/ir_utils.py:1969: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 's_pluses' of function 'find_best_threshold'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"<ipython-input-29-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "<ipython-input-26-e47a16af2a40>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"weak_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-26-e47a16af2a40> (4)\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 4:\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "    <source elided>\n",
      "    # return 1. if (polarity * f(x)) < (polarity * theta) else 0.\n",
      "    return (np.sign((polarity * theta) - (polarity * f(x))) + 1) // 2\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"weak_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 2:\n",
      "@jit\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 2:\n",
      "@jit\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=1/5 1.69s (1.69s in this stage) 1/63960 0.00% evaluated. Classification error improved to 0.33493 using Feature2h(x=0, y=0, width=2, height=1) ...\n",
      "t=1/5 2.23s (2.23s in this stage) 5/63960 0.01% evaluated. Classification error improved to 0.27158 using Feature2h(x=0, y=4, width=2, height=1) ...\n",
      "t=1/5 5.51s (5.51s in this stage) 29/63960 0.04% evaluated. Classification error improved to 0.25668 using Feature2h(x=1, y=9, width=2, height=1) ...\n",
      "t=1/5 14.83s (14.83s in this stage) 106/63960 0.16% evaluated. Classification error improved to 0.24801 using Feature2h(x=5, y=10, width=2, height=1) ...\n",
      "t=1/5 21.89s (21.88s in this stage) 160/63960 0.25% evaluated. Classification error improved to 0.17865 using Feature2h(x=8, y=7, width=2, height=1) ...\n",
      "t=1/5 58.30s (58.30s in this stage) 491/63960 0.77% evaluated. Classification error improved to 0.15210 using Feature2h(x=8, y=4, width=2, height=2) ...\n",
      "t=1/5 100.07s (100.07s in this stage) 805/63960 1.26% evaluated. Classification error improved to 0.15058 using Feature2h(x=8, y=2, width=2, height=3) ...\n",
      "t=1/5 100.62s (100.62s in this stage) 806/63960 1.26% evaluated. Classification error improved to 0.14808 using Feature2h(x=8, y=3, width=2, height=3) ...\n",
      "t=1/5 140.05s (140.05s in this stage) 1104/63960 1.72% evaluated. Classification error improved to 0.14358 using Feature2h(x=8, y=3, width=2, height=4) ...\n",
      "t=1/5 253.02s (253.02s in this stage) 1889/63960 2.95% evaluated. Classification error improved to 0.13208 using Feature2h(x=8, y=2, width=2, height=7) ...\n",
      "t=1/5 253.60s (253.60s in this stage) 1890/63960 2.95% evaluated. Classification error improved to 0.12683 using Feature2h(x=8, y=3, width=2, height=7) ...\n",
      "t=1/5 286.71s (286.71s in this stage) 2115/63960 3.31% evaluated. Classification error improved to 0.12682 using Feature2h(x=8, y=2, width=2, height=8) ...\n",
      "t=1/5 314.04s (314.04s in this stage) 2323/63960 3.63% evaluated. Classification error improved to 0.12658 using Feature2h(x=8, y=2, width=2, height=9) ...\n",
      "t=1/5 335.53s (335.53s in this stage) 2512/63960 3.93% evaluated. Classification error improved to 0.12658 using Feature2h(x=8, y=1, width=2, height=10) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-e47a16af2a40>:6: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"run_weak_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-26-e47a16af2a40> (8)\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 8:\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "    return weak_classifier(x=x, f=c.classifier, polarity=c.polarity, theta=c.threshold)\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"run_weak_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 7:\n",
      "@jit\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-26-e47a16af2a40>\", line 7:\n",
      "@jit\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building weak classifier 2/5 ...\n",
      "t=2/5 8649.41s (0.52s in this stage) 1/63960 0.00% evaluated. Classification error improved to 0.31558 using Feature2h(x=0, y=0, width=2, height=1) ...\n",
      "t=2/5 8649.93s (1.03s in this stage) 5/63960 0.01% evaluated. Classification error improved to 0.29233 using Feature2h(x=0, y=4, width=2, height=1) ...\n",
      "t=2/5 8679.34s (30.45s in this stage) 263/63960 0.41% evaluated. Classification error improved to 0.28143 using Feature2h(x=13, y=15, width=2, height=1) ...\n",
      "t=2/5 8687.93s (39.04s in this stage) 334/63960 0.52% evaluated. Classification error improved to 0.26122 using Feature2h(x=17, y=10, width=2, height=1) ...\n",
      "t=2/5 8721.66s (72.76s in this stage) 569/63960 0.89% evaluated. Classification error improved to 0.24411 using Feature2h(x=12, y=10, width=2, height=2) ...\n",
      "t=2/5 8985.54s (336.64s in this stage) 2569/63960 4.02% evaluated.\n",
      "t=2/5 9128.36s (479.46s in this stage) 3659/63960 5.72% evaluated. Classification error improved to 0.22927 using Feature2h(x=12, y=10, width=4, height=1) ...\n",
      "t=2/5 9546.47s (897.58s in this stage) 6680/63960 10.44% evaluated. Classification error improved to 0.21389 using Feature2h(x=11, y=10, width=6, height=1) ...\n",
      "t=2/5 9815.43s (1166.53s in this stage) 8680/63960 13.57% evaluated.\n",
      "t=2/5 10963.35s (2314.45s in this stage) 17511/63960 27.38% evaluated. Classification error improved to 0.19796 using Feature2v(x=4, y=4, width=1, height=4) ...\n",
      "t=2/5 11209.71s (2560.81s in this stage) 19482/63960 30.46% evaluated. Classification error improved to 0.19677 using Feature2v(x=4, y=3, width=2, height=6) ...\n",
      "t=2/5 11422.67s (2773.77s in this stage) 21054/63960 32.92% evaluated. Classification error improved to 0.19443 using Feature2v(x=3, y=3, width=3, height=6) ...\n",
      "t=2/5 11587.93s (2939.04s in this stage) 22217/63960 34.73% evaluated. Classification error improved to 0.19182 using Feature2v(x=14, y=4, width=4, height=2) ...\n",
      "Building weak classifier 3/5 ...\n",
      "t=3/5 17148.59s (0.53s in this stage) 1/63960 0.00% evaluated. Classification error improved to 0.33082 using Feature2h(x=0, y=0, width=2, height=1) ...\n",
      "t=3/5 17149.12s (1.06s in this stage) 5/63960 0.01% evaluated. Classification error improved to 0.30106 using Feature2h(x=0, y=4, width=2, height=1) ...\n",
      "t=3/5 17160.77s (12.71s in this stage) 104/63960 0.16% evaluated. Classification error improved to 0.29053 using Feature2h(x=5, y=8, width=2, height=1) ...\n",
      "t=3/5 17194.69s (46.64s in this stage) 351/63960 0.55% evaluated. Classification error improved to 0.27490 using Feature2h(x=0, y=8, width=2, height=2) ...\n",
      "t=3/5 17203.16s (55.10s in this stage) 433/63960 0.68% evaluated. Classification error improved to 0.27420 using Feature2h(x=5, y=0, width=2, height=2) ...\n",
      "t=3/5 17215.96s (67.90s in this stage) 525/63960 0.82% evaluated. Classification error improved to 0.27235 using Feature2h(x=10, y=2, width=2, height=2) ...\n",
      "t=3/5 17238.42s (90.36s in this stage) 659/63960 1.03% evaluated. Classification error improved to 0.24357 using Feature2h(x=17, y=10, width=2, height=2) ...\n",
      "t=3/5 17473.44s (325.38s in this stage) 2477/63960 3.87% evaluated. Classification error improved to 0.24018 using Feature2h(x=4, y=6, width=2, height=10) ...\n",
      "t=3/5 17648.19s (500.13s in this stage) 3804/63960 5.95% evaluated. Classification error improved to 0.23801 using Feature2h(x=4, y=7, width=4, height=2) ...\n",
      "t=3/5 17809.34s (661.28s in this stage) 5054/63960 7.90% evaluated. Classification error improved to 0.23272 using Feature2h(x=3, y=10, width=4, height=7) ...\n",
      "t=3/5 17882.10s (734.04s in this stage) 5617/63960 8.78% evaluated. Classification error improved to 0.22748 using Feature2h(x=3, y=6, width=4, height=10) ...\n",
      "t=3/5 19845.99s (2697.93s in this stage) 20662/63960 32.30% evaluated. Classification error improved to 0.21722 using Feature2v(x=12, y=15, width=3, height=2) ...\n",
      "Building weak classifier 4/5 ...\n",
      "t=4/5 25594.06s (0.53s in this stage) 3/63960 0.00% evaluated. Classification error improved to 0.40408 using Feature2h(x=0, y=2, width=2, height=1) ...\n",
      "t=4/5 25594.59s (1.06s in this stage) 7/63960 0.01% evaluated. Classification error improved to 0.40368 using Feature2h(x=0, y=6, width=2, height=1) ...\n",
      "t=4/5 25595.12s (1.59s in this stage) 8/63960 0.01% evaluated. Classification error improved to 0.33485 using Feature2h(x=0, y=7, width=2, height=1) ...\n",
      "t=4/5 25595.64s (2.11s in this stage) 9/63960 0.01% evaluated. Classification error improved to 0.30276 using Feature2h(x=0, y=8, width=2, height=1) ...\n",
      "t=4/5 25604.58s (11.05s in this stage) 104/63960 0.16% evaluated. Classification error improved to 0.27466 using Feature2h(x=5, y=8, width=2, height=1) ...\n",
      "t=4/5 25605.11s (11.58s in this stage) 106/63960 0.16% evaluated. Classification error improved to 0.27326 using Feature2h(x=5, y=10, width=2, height=1) ...\n",
      "t=4/5 25605.64s (12.11s in this stage) 107/63960 0.17% evaluated. Classification error improved to 0.25371 using Feature2h(x=5, y=11, width=2, height=1) ...\n",
      "t=4/5 25645.67s (52.14s in this stage) 440/63960 0.69% evaluated. Classification error improved to 0.25197 using Feature2h(x=5, y=7, width=2, height=2) ...\n",
      "t=4/5 25769.13s (175.60s in this stage) 1343/63960 2.10% evaluated. Classification error improved to 0.24775 using Feature2h(x=5, y=7, width=2, height=5) ...\n",
      "t=4/5 25936.86s (343.33s in this stage) 2653/63960 4.15% evaluated. Classification error improved to 0.24461 using Feature2h(x=4, y=6, width=2, height=11) ...\n",
      "t=4/5 26135.49s (541.96s in this stage) 4088/63960 6.39% evaluated. Classification error improved to 0.23213 using Feature2h(x=4, y=7, width=4, height=3) ...\n",
      "t=4/5 26223.59s (630.06s in this stage) 4834/63960 7.56% evaluated. Classification error improved to 0.22616 using Feature2h(x=3, y=11, width=4, height=6) ...\n",
      "t=4/5 26497.57s (904.04s in this stage) 6834/63960 10.68% evaluated.\n",
      "t=4/5 27917.66s (2324.13s in this stage) 17511/63960 27.38% evaluated. Classification error improved to 0.21886 using Feature2v(x=4, y=4, width=1, height=4) ...\n",
      "t=4/5 28194.82s (2601.29s in this stage) 19482/63960 30.46% evaluated. Classification error improved to 0.20661 using Feature2v(x=4, y=3, width=2, height=6) ...\n",
      "t=4/5 33403.73s (7810.20s in this stage) 58633/63960 91.67% evaluated. Classification error improved to 0.17794 using Feature4(x=4, y=0, width=4, height=12) ...\n",
      "t=4/5 33686.24s (8092.71s in this stage) 60633/63960 94.80% evaluated.\n",
      "t=4/5 33970.33s (8376.80s in this stage) 62633/63960 97.92% evaluated.\n",
      "Building weak classifier 5/5 ...\n",
      "t=5/5 34143.48s (0.52s in this stage) 2/63960 0.00% evaluated. Classification error improved to 0.33171 using Feature2h(x=0, y=1, width=2, height=1) ...\n",
      "t=5/5 34144.54s (1.58s in this stage) 5/63960 0.01% evaluated. Classification error improved to 0.25325 using Feature2h(x=0, y=4, width=2, height=1) ...\n",
      "t=5/5 37278.95s (3135.99s in this stage) 23473/63960 36.70% evaluated. Classification error improved to 0.24244 using Feature2v(x=4, y=0, width=5, height=2) ...\n",
      "t=5/5 37932.27s (3789.31s in this stage) 28351/63960 44.32% evaluated. Classification error improved to 0.24201 using Feature2v(x=5, y=0, width=9, height=2) ...\n",
      "t=5/5 38197.39s (4054.43s in this stage) 30351/63960 47.45% evaluated.\n",
      "t=5/5 38457.17s (4314.21s in this stage) 32351/63960 50.58% evaluated.\n",
      "t=5/5 42296.08s (8153.13s in this stage) 60655/63960 94.83% evaluated. Classification error improved to 0.24125 using Feature4(x=4, y=10, width=8, height=6) ...\n",
      "t=5/5 42564.72s (8421.76s in this stage) 62655/63960 97.96% evaluated.\n",
      "Done building 5 weak classifiers.\n"
     ]
    }
   ],
   "source": [
    "weak_classifiers_5, w_history = build_weak_classifiers('5 rounds', 5, xis, ys, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WeakClassifier(threshold=-2.414795756340027, polarity=1, alpha=1.9315405703473476, classifier=Feature2h(x=8, y=1, width=2, height=10)),\n",
       " WeakClassifier(threshold=1.1981849670410156, polarity=-1, alpha=1.4382275207572313, classifier=Feature2v(x=14, y=4, width=4, height=2)),\n",
       " WeakClassifier(threshold=0.23963642120361328, polarity=-1, alpha=1.2819242706852847, classifier=Feature2v(x=12, y=15, width=3, height=2)),\n",
       " WeakClassifier(threshold=-4.424053192138672, polarity=1, alpha=1.530361913268545, classifier=Feature4(x=4, y=0, width=4, height=12)),\n",
       " WeakClassifier(threshold=1.585296630859375, polarity=-1, alpha=1.1458350025396984, classifier=Feature4(x=4, y=10, width=8, height=6))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_classifiers_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"strong_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-27-886b5b384fd2> (3)\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 3:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    sum_hypotheses = 0.\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "<ipython-input-27-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"strong_classifier\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"strong_classifier\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 2:\n",
      "@jit\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 2:\n",
      "@jit\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "<ipython-input-27-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"strong_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-27-886b5b384fd2> (5)\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"strong_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-27-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84 , False Positives: 61, False Negatives: 337\n"
     ]
    }
   ],
   "source": [
    "ys_strong = np.array([strong_classifier(x, weak_classifiers) for x in test_xis])\n",
    "c, s = predict(test_ys, ys_strong)\n",
    "print(f'Accuracy: {(s.tp+s.tn)/(s.tp+s.fp+s.tn+s.fn):.2f} , False Positives: {s.fp}, False Negatives: {s.fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building weak classifier 1/3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-51fd85f81679>:19: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"find_best_threshold\" failed type inference due to: Invalid use of Function(<class 'float'>) with argument(s) of type(s): (Literal[str](inf))\n",
      " * parameterized\n",
      "In definition 0:\n",
      "    TypeError: float() only support for numbers\n",
      "    raised from /home/angshul1994/.local/lib/python3.6/site-packages/numba/typing/builtins.py:889\n",
      "In definition 1:\n",
      "    TypeError: float() only support for numbers\n",
      "    raised from /home/angshul1994/.local/lib/python3.6/site-packages/numba/typing/builtins.py:889\n",
      "This error is usually caused by passing an argument of a type that is unsupported by the named function.\n",
      "[1] During: resolving callee type: Function(<class 'float'>)\n",
      "[2] During: typing of call at <ipython-input-38-51fd85f81679> (21)\n",
      "\n",
      "\n",
      "File \"<ipython-input-38-51fd85f81679>\", line 21:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    min_e = float('inf')\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "<ipython-input-38-51fd85f81679>:19: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"find_best_threshold\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-38-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"find_best_threshold\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-38-51fd85f81679>\", line 20:\n",
      "@jit\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-38-51fd85f81679>\", line 20:\n",
      "@jit\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/ir_utils.py:1969: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 's_minuses' of function 'find_best_threshold'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"<ipython-input-38-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/ir_utils.py:1969: NumbaPendingDeprecationWarning: \n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 's_pluses' of function 'find_best_threshold'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\n",
      "File \"<ipython-input-38-51fd85f81679>\", line 23:\n",
      "def find_best_threshold(zs: np.ndarray, t_minus: float, t_plus: float, s_minuses: List[float], s_pluses: List[float]) -> ThresholdPolarity:\n",
      "    <source elided>\n",
      "    min_z, polarity = 0, 0\n",
      "    for z, s_m, s_p in zip(zs, s_minuses, s_pluses):\n",
      "    ^\n",
      "\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "<ipython-input-35-e47a16af2a40>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"weak_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-35-e47a16af2a40> (4)\n",
      "\n",
      "File \"<ipython-input-35-e47a16af2a40>\", line 4:\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "    <source elided>\n",
      "    # return 1. if (polarity * f(x)) < (polarity * theta) else 0.\n",
      "    return (np.sign((polarity * theta) - (polarity * f(x))) + 1) // 2\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"weak_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-35-e47a16af2a40>\", line 2:\n",
      "@jit\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-35-e47a16af2a40>\", line 2:\n",
      "@jit\n",
      "def weak_classifier(x: np.ndarray, f: Feature, polarity: float, theta: float) -> float:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=1/3 1.83s (1.83s in this stage) 1/63960 0.00% evaluated. Classification error improved to 0.33393 using Feature2h(x=0, y=0, width=2, height=1) ...\n",
      "t=1/3 2.41s (2.41s in this stage) 5/63960 0.01% evaluated. Classification error improved to 0.26404 using Feature2h(x=0, y=4, width=2, height=1) ...\n",
      "t=1/3 5.90s (5.90s in this stage) 29/63960 0.04% evaluated. Classification error improved to 0.25669 using Feature2h(x=1, y=9, width=2, height=1) ...\n",
      "t=1/3 15.74s (15.74s in this stage) 106/63960 0.16% evaluated. Classification error improved to 0.24652 using Feature2h(x=5, y=10, width=2, height=1) ...\n",
      "t=1/3 23.26s (23.26s in this stage) 160/63960 0.25% evaluated. Classification error improved to 0.17865 using Feature2h(x=8, y=7, width=2, height=1) ...\n",
      "t=1/3 62.32s (62.32s in this stage) 491/63960 0.77% evaluated. Classification error improved to 0.15235 using Feature2h(x=8, y=4, width=2, height=2) ...\n",
      "t=1/3 107.63s (107.63s in this stage) 805/63960 1.26% evaluated. Classification error improved to 0.15082 using Feature2h(x=8, y=2, width=2, height=3) ...\n",
      "t=1/3 108.22s (108.22s in this stage) 806/63960 1.26% evaluated. Classification error improved to 0.14759 using Feature2h(x=8, y=3, width=2, height=3) ...\n",
      "t=1/3 150.05s (150.05s in this stage) 1104/63960 1.72% evaluated. Classification error improved to 0.14383 using Feature2h(x=8, y=3, width=2, height=4) ...\n",
      "t=1/3 271.96s (271.96s in this stage) 1889/63960 2.95% evaluated. Classification error improved to 0.13208 using Feature2h(x=8, y=2, width=2, height=7) ...\n",
      "t=1/3 272.55s (272.55s in this stage) 1890/63960 2.95% evaluated. Classification error improved to 0.12708 using Feature2h(x=8, y=3, width=2, height=7) ...\n",
      "t=1/3 308.99s (308.98s in this stage) 2115/63960 3.31% evaluated. Classification error improved to 0.12707 using Feature2h(x=8, y=2, width=2, height=8) ...\n",
      "t=1/3 338.50s (338.50s in this stage) 2323/63960 3.63% evaluated. Classification error improved to 0.12683 using Feature2h(x=8, y=2, width=2, height=9) ...\n",
      "t=1/3 361.80s (361.80s in this stage) 2512/63960 3.93% evaluated. Classification error improved to 0.12658 using Feature2h(x=8, y=1, width=2, height=10) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-e47a16af2a40>:6: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"run_weak_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-35-e47a16af2a40> (8)\n",
      "\n",
      "File \"<ipython-input-35-e47a16af2a40>\", line 8:\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "    return weak_classifier(x=x, f=c.classifier, polarity=c.polarity, theta=c.threshold)\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"run_weak_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-35-e47a16af2a40>\", line 7:\n",
      "@jit\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-35-e47a16af2a40>\", line 7:\n",
      "@jit\n",
      "def run_weak_classifier(x: np.ndarray, c: WeakClassifier) -> float:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building weak classifier 2/3 ...\n",
      "t=2/3 9410.01s (0.57s in this stage) 1/63960 0.00% evaluated. Classification error improved to 0.31500 using Feature2h(x=0, y=0, width=2, height=1) ...\n",
      "t=2/3 9410.60s (1.16s in this stage) 5/63960 0.01% evaluated. Classification error improved to 0.29445 using Feature2h(x=0, y=4, width=2, height=1) ...\n",
      "t=2/3 9443.07s (33.64s in this stage) 263/63960 0.41% evaluated. Classification error improved to 0.28275 using Feature2h(x=13, y=15, width=2, height=1) ...\n",
      "t=2/3 9452.41s (42.97s in this stage) 334/63960 0.52% evaluated. Classification error improved to 0.26040 using Feature2h(x=17, y=10, width=2, height=1) ...\n",
      "t=2/3 9489.78s (80.35s in this stage) 569/63960 0.89% evaluated. Classification error improved to 0.24339 using Feature2h(x=12, y=10, width=2, height=2) ...\n",
      "t=2/3 9782.48s (373.04s in this stage) 2569/63960 4.02% evaluated.\n",
      "t=2/3 9941.74s (532.31s in this stage) 3659/63960 5.72% evaluated. Classification error improved to 0.23423 using Feature2h(x=12, y=10, width=4, height=1) ...\n",
      "t=2/3 10404.60s (995.17s in this stage) 6680/63960 10.44% evaluated. Classification error improved to 0.21389 using Feature2h(x=11, y=10, width=6, height=1) ...\n",
      "t=2/3 10703.39s (1293.95s in this stage) 8680/63960 13.57% evaluated.\n",
      "t=2/3 11980.67s (2571.24s in this stage) 17511/63960 27.38% evaluated. Classification error improved to 0.19753 using Feature2v(x=4, y=4, width=1, height=4) ...\n",
      "t=2/3 12252.79s (2843.35s in this stage) 19482/63960 30.46% evaluated. Classification error improved to 0.19741 using Feature2v(x=4, y=3, width=2, height=6) ...\n",
      "t=2/3 12488.65s (3079.21s in this stage) 21054/63960 32.92% evaluated. Classification error improved to 0.19429 using Feature2v(x=3, y=3, width=3, height=6) ...\n",
      "t=2/3 12669.69s (3260.26s in this stage) 22217/63960 34.73% evaluated. Classification error improved to 0.19182 using Feature2v(x=14, y=4, width=4, height=2) ...\n",
      "Building weak classifier 3/3 ...\n",
      "t=3/3 18825.56s (0.58s in this stage) 1/63960 0.00% evaluated. Classification error improved to 0.33530 using Feature2h(x=0, y=0, width=2, height=1) ...\n",
      "t=3/3 18826.14s (1.16s in this stage) 5/63960 0.01% evaluated. Classification error improved to 0.30741 using Feature2h(x=0, y=4, width=2, height=1) ...\n",
      "t=3/3 18839.01s (14.03s in this stage) 104/63960 0.16% evaluated. Classification error improved to 0.30097 using Feature2h(x=5, y=8, width=2, height=1) ...\n",
      "t=3/3 18873.77s (48.79s in this stage) 346/63960 0.54% evaluated. Classification error improved to 0.28527 using Feature2h(x=0, y=3, width=2, height=2) ...\n",
      "t=3/3 18876.12s (51.14s in this stage) 351/63960 0.55% evaluated. Classification error improved to 0.27381 using Feature2h(x=0, y=8, width=2, height=2) ...\n",
      "t=3/3 18927.21s (102.23s in this stage) 659/63960 1.03% evaluated. Classification error improved to 0.26441 using Feature2h(x=17, y=10, width=2, height=2) ...\n",
      "t=3/3 18944.37s (119.39s in this stage) 749/63960 1.17% evaluated. Classification error improved to 0.26399 using Feature2h(x=4, y=14, width=2, height=3) ...\n",
      "t=3/3 19000.17s (175.19s in this stage) 1098/63960 1.72% evaluated. Classification error improved to 0.25840 using Feature2h(x=7, y=13, width=2, height=4) ...\n",
      "t=3/3 19132.36s (307.38s in this stage) 2072/63960 3.24% evaluated. Classification error improved to 0.25728 using Feature2h(x=4, y=7, width=2, height=8) ...\n",
      "t=3/3 19183.55s (358.57s in this stage) 2477/63960 3.87% evaluated. Classification error improved to 0.24027 using Feature2h(x=4, y=6, width=2, height=10) ...\n",
      "t=3/3 19558.92s (733.94s in this stage) 5054/63960 7.90% evaluated. Classification error improved to 0.23260 using Feature2h(x=3, y=10, width=4, height=7) ...\n",
      "t=3/3 19637.91s (812.93s in this stage) 5617/63960 8.78% evaluated. Classification error improved to 0.22748 using Feature2h(x=3, y=6, width=4, height=10) ...\n",
      "t=3/3 21823.13s (2998.15s in this stage) 20644/63960 32.27% evaluated. Classification error improved to 0.22505 using Feature2v(x=11, y=15, width=3, height=2) ...\n",
      "t=3/3 21826.05s (3001.07s in this stage) 20662/63960 32.30% evaluated. Classification error improved to 0.21694 using Feature2v(x=12, y=15, width=3, height=2) ...\n",
      "Done building 3 weak classifiers.\n"
     ]
    }
   ],
   "source": [
    "weak_classifiers_3, w_history = build_weak_classifiers_3('3 rounds', 3, xis, ys, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"strong_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-36-886b5b384fd2> (3)\n",
      "\n",
      "File \"<ipython-input-36-886b5b384fd2>\", line 3:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    sum_hypotheses = 0.\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "<ipython-input-36-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"strong_classifier\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"<ipython-input-36-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"strong_classifier\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"<ipython-input-36-886b5b384fd2>\", line 2:\n",
      "@jit\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-36-886b5b384fd2>\", line 2:\n",
      "@jit\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "<ipython-input-36-886b5b384fd2>:1: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"strong_classifier\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at <ipython-input-36-886b5b384fd2> (5)\n",
      "\n",
      "File \"<ipython-input-36-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  @jit\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"strong_classifier\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"<ipython-input-36-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/angshul1994/.local/lib/python3.6/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"<ipython-input-36-886b5b384fd2>\", line 5:\n",
      "def strong_classifier(x: np.ndarray, weak_classifiers: List[WeakClassifier]) -> int:\n",
      "    <source elided>\n",
      "    sum_alphas = 0.\n",
      "    for c in weak_classifiers:\n",
      "    ^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84 , False Positives: 57, False Negatives: 347\n"
     ]
    }
   ],
   "source": [
    "ys_strong = np.array([strong_classifier(x, weak_classifiers_3) for x in test_xis])\n",
    "c, s = predict(test_ys, ys_strong)\n",
    "print(f'Accuracy: {(s.tp+s.tn)/(s.tp+s.fp+s.tn+s.fn):.2f} , False Positives: {s.fp}, False Negatives: {s.fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
